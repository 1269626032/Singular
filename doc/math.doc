@comment -*-texinfo-*-
@comment $Id: math.doc,v 1.54 2000-05-16 08:02:36 Singular Exp $
@comment this file contains the mathematical background of Singular

@c The following directives are necessary for proper compilation
@c with emacs (C-c C-e C-r).  Please keep it as it is.  Since it
@c is wrapped in `@ignore' and `@end ignore' it does not harm `tex' or
@c `makeinfo' but is a great help in editing this file (emacs
@c ignores the `@ignore').
@ignore
%**start
\input texinfo.tex
@setfilename math.info
@node Top, Mathematical background
@menu
* General concepts::
@end menu
@node Mathematical background, SINGULAR libraries, Examples, Top
@chapter Mathematical background
%**end
@end ignore

This chapter introduces some of the mathematical notions and definitions used
throughout the manual. It is mostly a collection of the
most prominent definitions and properties. For details, please, refer to
some articles or text books (see @ref{References}).

@menu
* Standard bases::
* Hilbert function::
* Syzygies and resolutions::
* Characteristic sets::
* The spectrum::
* Toric ideals and Integer Programming::
* References::
@end menu
@c ---------------------------------------------------------------------------
@node Standard bases, Hilbert function, ,Mathematical background
@section Standard bases
@cindex Standard bases

@subheading Definition
@tex
Let $R = \hbox{Loc}_< K[\underline{x}]$, let $I \subseteq R$ be
an ideal and let $L(I)$ denote the ideal in $R$ generated by the leading
terms, i.e., by $\left\{L(f) \mid f \in I\right\}$. Then, $f_1, \ldots, f_s \in I$
is called a {\bf standard basis} of $I$ if $L(f_1), \ldots, L(f_s)$
generate the ideal \hbox{$L(I) \subset R$}.
@end tex
@ifinfo
Let R = Loc K[x], let I in R be an ideal and let L(I) denote the ideal in R
generated by the leading terms, i.e., by @{ L(f) | f in I@}. Then, f_1,
@dots{}, f_s in I is called a @strong{standard basis} of I if L(f_1),
@dots{}, L(f_s) generate the ideal L(I) in R.
@end ifinfo

@subheading Properties
@table @asis
@item normal form:
@cindex Normal form
@tex
A function $\hbox{NF} : R^r \times \{G \mid G\ \hbox{ a standard
basis}\} \to R^r, (p,G) \mapsto \hbox{NF}(p|G)$, is called a {\bf normal
form} if for any $p \in R^r$ and any standard basis $G$ the following
holds: if $\hbox{NF}(p|G) \not= 0$ then $L(g)$ does not divide
$L(\hbox{NF}(p|G))$ for all $g \in G$.

\noindent
$\hbox{NF}(p|G)$ is called a {\bf normal form of} $p$ {\bf with
respect to} $G$ (note that such a function is not unique).
@end tex
@ifinfo
A function NF : R^r x @{G | G a standard basis@} -> R^r, (p,G) ->
NF(p|G), is called a @strong{normal form} if for any p in R^r and any
standard basis G the following holds: if NF(p|G) <> 0 then L(g) does not
divide L(NF(p|G)) for all g in G.
@*NF(p|G) is called a @strong{normal form} of p with respect to G (note
that such a function is not unique).
@end ifinfo
@item ideal membership:
@cindex Ideal membership
@tex
$f \in I$ if and only if $\hbox{NF}(f,\hbox{std}(I)) = 0$ (for $I
\subseteq R$, resp.\ $I \subseteq R^r$).
@end tex
@ifinfo
f in I if and only if NF(f,std(I)) = 0 (for I in R, resp.@: I in R^r).
@end ifinfo
@item Hilbert function:
@tex
Let \hbox{$I \subseteq K[\underline{x}]^r$} be a homogeneous ideal, then the Hilbert function
$H_I$ of $I$ (see below)
and the Hilbert function $H_{L(I)}$ of the leading ideal $L(I)$
coincide, i.e.,
$H_I=H_{L(I)}$.
@end tex
@ifinfo
Let I in K[x]^r be a homogeneous ideal, then the Hilbert function H_I of I
and the Hilbert function H_L(I) of the leading ideal L(I) coincide.
@end ifinfo
@end table

@c ---------------------------------------------------------------------------
@node Hilbert function, Syzygies and resolutions, Standard bases, Mathematical background
@section Hilbert function
@cindex Hilbert function
@cindex Hilbert series
@tex
Let M $=\bigoplus_i M_i$ be a graded module over $K[x_1,..,x_n]$ with 
respect to weights $(w_1,..w_n)$.
The {\bf Hilbert function} of $M$, $H_M$, is defined (on the integers) by
$$H_M(k) :=dim_K M_k.$$
The {\bf Hilbert-Poincare series}  of $M$ is the power series
$$\hbox{HP}_M(t) :=\sum_{i=-\infty}^\infty
H_M(i)t^i=\sum_{i=-\infty}^\infty dim_K M_i \cdot t^i.$$
It turns out that $\hbox{HP}_M(t)$ can be written in two useful ways
for weights $(1,..,1)$:
$$\hbox{HP}_M(t)={Q(t)\over (1-t)^n}={P(t)\over (1-t)^{dim(M)}}$$
where $Q(t)$ and $P(t)$ are polynomials in ${\bf Z}[t]$.
$Q(t)$ is called the {\bf first Hilbert series},
and $P(t)$ the {\bf second Hilbert series}.
If \hbox{$P(t)=\sum_{k=0}^N a_k t^k$}, and \hbox{$d = dim(M)$},
then \hbox{$H_M(s)=\sum_{k=0}^N a_k$ ${d+s-k-1}\choose{d-1}$}
(the {\bf Hilbert polynomial}) for $s \ge N$.
@end tex
@ifinfo
Let M =(+) M_i be a graded module over K[x_1,...,x_n] with
respect to weights (w_1,..w_n).
The Hilbert function of M H_M is defined by
@display
H_M(k)=dim_K M_k.
@end display
The Hilbert-Poincare series  of M is the power series
@display
HP_M(t)=sum_i dim_K (M_i)*t^i.
@end display
It turns out that HP_M(t) can be written in two useful ways
for weights $(1,..,1)$:
@display
H_M(t)=Q(t)/(1-t)^n=P(t)/(1-t)^dim(M).
@end display
where Q(t) and P(t) are polynomials in Z[t].
Q(t) is called the first Hilbert series, and P(t) the second Hilbert series.
If P(t)=sum_(k=0)^N a_k t^k, and d=dim(M),
then
@display
H_M(s)=sum_(k=0)^N a_k binomial(d+s-k-1,d-1) (the Hilbert polynomial)
@end display
for s >= N.
@end ifinfo
@*
@*
@tex
Generalizing these to quasihomogeneous modules we get
$$\hbox{HP}_M(t)={Q(t)\over {\Pi_{i=1}^n(1-t^{w_i})}}$$
where $Q(t)$ is a polynomial in ${\bf Z}[t]$.
$Q(t)$ is called the {\bf first (weighted) Hilbert series} of M.
@end tex
@ifinfo
Generalizing these to quasihomogeneous modules we get
@display
H_M(t)=Q(t)/Prod((1-t)^(w_i)).
@end display
where Q(t) is a polynomial in Z[t].
Q(t) is called the first (weighted) Hilbert series of M.
@end ifinfo

@c ---------------------------------------------------------------------------
@node Syzygies and resolutions, Characteristic sets, Hilbert function, Mathematical background
@section Syzygies and resolutions
@cindex Syzygies and resolutions

@subheading Syzygies
@tex
Let $R = \hbox{Loc}_< K[\underline{x}]$ and let \hbox{$I=(g_1, ..., g_s)
\subseteq R^r$}.  Then, the {\bf module of syzygies} (or {\bf 1st syzygy
module}, {\bf module of relations}) of $I$, syz($I$), is defined to be the
kernel of the map \hbox{$R^s \rightarrow R^r,\; \sum_{i=1}^s w_ie_i \mapsto
\sum_{i=1}^s w_ig_i$.}
@end tex
@ifinfo
Let R=Loc K[x] and let I=(g_1, ..., g_s) in R^r. Then, the @strong{module
of syzygies} (or @strong{1st syzygy module}, @strong{module of relations})
of I, syz(I), is defined to be the kernel of the map
@display
R^s --> R^r,
w_1*e_1 + ... + w_s*e_s -> w_1*g_1 + ... + w_s*g_s.
@end display
@end ifinfo

The @strong{k-th syzygy module} is defined inductively to be the module
of syzygies of the
@tex
$(k-1)$-st
@end tex
@ifinfo
(k-1)-st
@end ifinfo
syzygy module.

Note, that the syzygy modules of @math{I} are uniquely defined up to direct
summands.

@table @code
@item @strong{Example:}
@smallexample
@c example
  ring R= 0,(u,v,x,y,z),dp;
  ideal i=ux, vx, uy, vy;
  print(syz(i));
@c example
@end smallexample
@end table

@subheading Free resolutions
@tex
Let $I=(g_1,...,g_s)\subseteq R^r$ and $M= R^r/I$.
A {\bf free resolution of $M$} is a long exact sequence
$$...\longrightarrow F_2 \buildrel{A_2}\over{\longrightarrow} F_1
\buildrel{A_1}\over{\longrightarrow} F_0\longrightarrow M\longrightarrow
0,$$
@end tex
@ifinfo
Let I=(g_1,...,g_s) in R^r and M=R^r/I.  A free resolution of M is a
long exact sequence
@display
...--> F2 --A2-> F1 --A1-> F0-->M-->0,
@end display
@end ifinfo
@*where the columns of the matrix
@tex
$A_1$
@end tex
@ifinfo
A_1
@end ifinfo
generate @math{I}. Note, that resolutions need not to be finite (i.e., of
finite length). The Hilbert Syzygy Theorem states, that for @math{R} a
graded ring and
@tex
$I \subset R^r$
@end tex
@ifinfo
I in R^r
@end ifinfo
a graded submodule, resp.@: @math{R} local (a power series ring), there
exists a ("minimal") resolution of length not exceeding the number of
variables of @math{R}.

@table @code
@item @strong{Example:}
@smallexample
@c example
  ring R= 0,(u,v,x,y,z),dp;
  ideal I = ux, vx, uy, vy;
  resolution resI = mres(I,0); resI;
  // The matrix A_1 is given by
  print(matrix(resI[1]));
  // We see that the columns of A_1 generate I.
  // The matrix A_2 is given by
  print(matrix(resI[3]));
@c example
@end smallexample
@end table

@subheading Betti numbers and regularity
@cindex Betti number
@cindex regularity
@tex
Let $R$ be a graded ring (e.g., $R = \hbox{Loc}_< K[\underline{x}]$) and
let $I \subset R^r$ be a graded submodule. Let
$$
  R^r = \bigoplus_a R\cdot e_{a,0} \buildrel A_1 \over \longleftarrow
        \bigoplus_a R\cdot e_{a,1} \longleftarrow \ldots \longleftarrow
        \bigoplus_a R\cdot e_{a,n} \longleftarrow 0
$$
be a minimal free resolution of $R^n/I$ considered with homogeneous maps
of degree 0. Then the {\bf graded Betti number} $b_{i,j}$ of $R^r/I$ is
the minimal number of generators $e_{a,j}$ in degree $i+j$ of the $j$-th
syzygy module of $R^r/I$ (i.e., the $(j-1)$-st syzygy module of
$I$). Note, that by definition the 0th syzygy module of $R^r/I$ is $R^r$
and the 1st syzygy module of $R^r/I$ is $I$.
@end tex
@ifinfo
Let R be a graded ring (e.g., R = K[x]) and let I in R^r be a graded
submodule. Let
@display
R^r = (+) K[x]e(a,0) <--- (+) K[x]e(a,1)
            <--- @dots{} <--- (+) K[x]e(a,n) <--- 0
@end display
be a minimal free resolution of R^n/I considered with homogeneous maps
of degree 0. Then the @strong{graded Betti number} b_i,j of R^r/I is the
minimal number of generators e_a,j in degree i+j of the j-th syzygy
module of R^r/I (i.e., the (j-1)-st syzygy module of I). Note, that by
definition the 0th syzygy module of R^r/I is R^r and the 1st syzygy module
of R^r/I is I.
@end ifinfo

The @strong{regularity} of @math{I} is the smallest integer @math{s}
such that
@tex
$$
    \hbox{deg}(e_{a,j}) \le s+j-1 \quad \hbox{for all $j$.}
$$
@end tex
@ifinfo
@display
deg(e(a,j)) <= s+j-1    for all j.
@end display
@end ifinfo

@table @code
@item @strong{Example:}
@smallexample
@c example
  ring R= 0,(u,v,x,y,z),dp;
  ideal I = ux, vx, uy, vy;
  resolution resI = mres(I,0); resI;
  // the betti number:
  print(betti(resI), "betti");
  // the regularity:
  regularity(resI);
@c example
@end smallexample
@end table
@c ---------------------------------------------------------------------------
@node Characteristic sets, The spectrum, Syzygies and resolutions, Mathematical background
@section Characteristic sets
@cindex Characteristic sets

@tex
Let $<$ be the lexicographical ordering on $R=K[x_1,...,x_n]$ with $x_1
< ... < x_n$.
For $f \in R$ let lvar($f$) (the leading variable of $f$) be the largest
variable in $f$,
i.e., if $f=a_s(x_1,...,x_{k-1})x_k^s+...+a_0(x_1,...,x_{k-1})$ for some
$k \leq n$ then lvar$(f)=x_k$.

Moreover, let
\hbox{ini}$(f):=a_s(x_1,...,x_{k-1})$. The pseudoremainder
$r=\hbox{prem}(g,f)$ of $g$ with respect to $f$ is
defined by the equality $\hbox{ini}(f)^a\cdot g = qf+r$ with
$\hbox{deg}_{lvar(f)}(r)<\hbox{deg}_{lvar(f)}(f)$ and $a$
minimal.

A set $T=\{f_1,...,f_r\} \subset R$ is called triangular if
$\hbox{lvar}(f_1)<...<\hbox{lvar}(f_r)$. Moreover, let $ U \subset T $,
then $(T,U)$ is called a triangular system, if $T$ is a triangular set
such that $\hbox{ini}(T)$ does not vanish on $V(T) \setminus V(U)
(=:V(T\setminus U))$.

$T$ is called irreducible if for every $i$ there are no
$d_i$,$f_i'$,$f_i''$ such that
$$   \hbox{lvar}(d_i)<\hbox{lvar}(f_i) =
\hbox{lvar}(f_i')=\hbox{lvar}(f_i''),$$
$$   0 \not\in \hbox{prem}(\{ d_i, \hbox{ini}(f_i'),
\hbox{ini}(f_i'')\},\{ f_1,...,f_{i-1}\}),$$
$$\hbox{prem}(d_if_i-f_i'f_i'',\{f_1,...,f_{i-1}\})=0.$$
Furthermore, $(T,U)$ is called irreducible if $T$ is irreducible.

The main result on triangular sets is the following:
let $G=\{g_1,...,g_s\} \subset R$ then there are irreducible triangular sets $T_1,...,T_l$
such that $V(G)=\bigcup_{i=1}^{l}(V(T_i\setminus I_i))$
where $I_i=\{\hbox{ini}(f) \mid f \in T_i \}$. Such a set
$\{T_1,...,T_l\}$ is called an {\bf irreducible characteristic series} of
the ideal $(G)$.
@end tex
@ifinfo
Let > be the lexicographical ordering on R=K[x_1,...,x_n] with x_1<...<x_n .
For f in R let lvar(f) (the leading variable of f) be the largest
variable in lead(f) (the leading term of f with respect to >),
i.e., if f=a_s(x_1,...,x_(k-1))x_k^s+...+a_0(x_1,...,x_(k-1)) for some
k<=n then lvar(f)=x_k.

Moreover, let ini(f):=a_s(x_1,...,x_(k-1)). The pseudoremainder
r=prem(g,f) of g with respect to f is defined by ini(f)^a*g=q*f+r with
the property deg_(lvar(f))(r)<deg_(lvar(f))(f), @code{a} minimal.

A set T=@{f_1,...,f_r@} in R is called triangular if lvar(f_1)<...<lvar(f_r).

(T,U) is called a triangular system, if U is a subset of T and
if T is a triangular set such that ini(T)
does not vanish on the zero-set of T \ zero-set of U
( =:Zero(T\U)).

T is called irreducible if for every i there are no d_i,f_i',f_i'' with
the property:
@display
lvar(d_i)<lvar(f_i)
lvar(f_i')=lvar(f_i'')=lvar(f_i)
0 not in prem(@{ d_i, ini(f_i'), ini(f_i'')@},@{ f_1,...,f_(i-1)@})
@end display
such that prem(d_i*f_i-f_i'*f_i'',@{f_1,...,f_(i-1)@})=0.

(T,U) is called irreducible if T is irreducible.

The main result on triangular sets is the following: let
G=@{g_1,...,g_s@} then there are irreducible triangular sets T_1,...,T_l
such that Zero(G)=Union(i=1,...,l: Zero(T_i\I_i)) where I_i=@{ini(f), f
in T_i @}.  Such a set @{T_1,...,T_l@} is called an @strong{irreducibel
characteristic series} of the ideal (G).
@end ifinfo

@table @code
@item @strong{Example:}
@smallexample
@c example
  ring R= 0,(x,y,z,u),dp;
  ideal i=-3zu+y2-2x+2,
          -3x2u-4yz-6xz+2y2+3xy,
          -3z2u-xu+y2z+y;
  print(char_series(i));
@c example
@end smallexample
@end table
@c ---------------------------------------------------------------------------
@node The spectrum, Toric ideals, Characteristic sets, Mathematical background
@section The spectrum
@cindex The spectrum

@c the following text contain too much math code, so there are
@c tex and info versions of it. It end just before the introducing text
@c to the first example.

@tex
Let $f\colon(C^n,0)\rightarrow(C,0)$ be an isolated
hypersurface singularity given by a polynomial wich we also
denote by $f$. Let $O=C[x_1,\ldots,x_n]_{(x_1,\ldots,x_n)}$
be the local ring at the origin and $J_f$ the jacobian ideal of $f$.
If the coefficients of $f$ are algebraic numbers,
{\sc Singular} can be used to compute invariants of $f$ such as
the Milnor number $\mu(f)=\dim_CO/J_f$ and
the Tjurina number $\tau(f)=\dim_CO/(J_f,f)$.

If in addition the principal part of $f$ is $C$-nondegenerate,
then also the spectrum of $f$ and the geometric genus $p_g(f)$
can be computed.

The spectrum of $f$ consists of $\mu(f)$ rational numbers
{\tt spectrum}$(f)=[\alpha_1,\ldots,\alpha_{\mu}]$ such that
$e^{2\pi i\alpha_1},\ldots,e^{2\pi i\alpha_\mu}$ are the eigenvalues
of the monodromy of $f$. These numbers are logarithms of the eigenvalues
determined by the mixed Hodge Structure on the cohomology of
the Milnor fibre of $f$. The spectrum numbers lie in the open interval
$(0,n)$, symmetric about the midpoint $n/2$. It is very interesting
how the spectrum behaves under deformations. To start with, it
is constant under $\mu$-constant deformations.

Then there is the so called semicontinuity.
If $F(x,t)$ is a deformation of $f$
(i.e.~$F(x,0)=f(x)$), then every half open
interval of length one $I=(a,a+1]$ is a semicontinuity domain
in the following sense: the number of spectrum numbers of $f$
in $I$ is greater or equal the number of spectrum numbers
of a small deformation $F(\ ,\varepsilon)$ in $I$:


$|{\tt spectrum}(f)\cap I| \geq \sum_{P\in Sing(F(\ ,\epsilon))}
    |{\tt spectrum}_P(F(\ ,\epsilon))\cap I| $

Note that on the right hand side we sum over all
singularities of the small deformation $F(\ ,\varepsilon)$.
Furthermore if $f$ is
semiquasihomogeneous, then also every open interval of length
one $I=(a,a+1)$ is a semicontinuity domain as above.

Two given isolated singularities $f$ and $g$ determine two spectra and from
these spectra we get an integer. This integer is the maximal number
$k\in{N}_0$
such that the semicontinuity holds for the spectrum of $f$ and
$k$ times the spectrum of $g$.
These numbers give bounds for the maximal number of isolated
singularties of a specific type on a hypersurface
$X\subset{P}^n$ of degree $d$: such a surface has a
smooth hyperplane section, and the complement is a small deformation
of a cone over this hyperplane section.
The cone itself being a $\mu$-constant deformation of
$x_1^d+\ldots+x_n^d=0$, the singularities are bounded
by the spectrum of $x_1^d+\ldots+x_n^d$.
@end tex

@ifinfo
Let f:(C^n,0) -> (C,0) be an isolated
hypersurface singularity given by a polynomial wich we also
denote by f. Let O = C[x_1, @dots{}, x_n]_(x_1, @dots{}, x_n)
be the local ring at the origin and J_f the jacobian ideal of f.
If the coefficients of f are algebraic numbers,
@sc{Singular} can be used to compute invariants of f such as
the Milnor number mu(f) = dim_C ( O/J_f ) and
the Tjurina number tau(f) = dim_C ( O/(J_f,f) ).

If in addition the principal part of f is C-nondegenerate,
then also the spectrum of f and the geometric genus p_g(f)
can be computed.

The spectrum of f consists of mu(f) rational numbers
spectrum(f) = [alpha_1, @dots{}, alpha_mu] such that
e^(2*pi*i*alpha_1), @dots{}, e^(2*pi*i*alpha_mu) are the eigenvalues
of the monodromy of f. These numbers are logarithms of the eigenvalues
determined by the mixed Hodge Structure on the cohomology of
the Milnor fibre of f. The spectrum numbers lie in the open interval
(0,n), symmetric about the midpoint n/2. It is very interesting
how the spectrum behaves under deformations. To start with, it
is constant under mu-constant deformations.

Then there is the so called semicontinuity.
If F(x,t) is a deformation of f
(i.e. F(x,0) = f(x)), then every half open
interval of length one I = (a,a+1] is a semicontinuity domain
in the following sense: the number of spectrum numbers of f
in I is greater or equal the number of spectrum numbers
of a small deformation F( ,epsilon) in I:


| spectrum(f) intersect I | >= sum | spectrum_P (F( ,epsilon)) intersect I |
over all P in Sing(F( ,epsilon))

Note that on the right hand side we sum over all
singularities of the small deformation F( ,epsilon).
Furthermore if f is
semiquasihomogeneous, then also every open interval of length
one I=(a,a+1) is a semicontinuity domain as above.

Two given isolated singularities f and g determine two spectra and from
these spectra we get an integer. This integer is the maximal number
k in N such that the semicontinuity holds for the spectrum of f and
k times the spectrum of g.
These numbers give bounds for the maximal number of isolated
singularties of a specific type on a hypersurface X in P^n of degree d:
such a surface has a smooth hyperplane section,
and the complement is a small deformation of a cone over this hyperplane
section. The cone itself being a mu-constant deformation of
x_1^d+@dots{}+x_n^d=0, the singularities are bounded
by the spectrum of x_1^d+@dots{}+x_n^d.
@end ifinfo

Let us calculate one specific example, the maximal number of
triple points of type
@tex
$\tilde{E}_6$ on a surface $X\subset{P}^3$
@end tex
@ifinfo
E~_6 on a surface X in P^3
@end ifinfo
of degree seven.
This calculation can be done over the rationals.
So choose a local ordering on @math{Q[x,y,z]}. Here we take the
negative degree lexicographical ordering which is denoted
@code{ds} in @sc{Singular}:

@smallexample
@c STILL BROKEN @c example
ring r=0,(x,y,z),ds;
LIB "spectrum.lib";
poly f=x^7+y^7+z^7;
list s1=spectrum( f );
s1;
@c STILL BROKEN @c example
@end smallexample

The command @code{spectrum(f)} computes the spectrum of @math{f} and
returns a list with six entries:
The Milnor number
@tex
$\mu(f)$, the geometric genus $p_g(f)$
@end tex
@ifinfo
mu(f), the geometric genus p_g(f)
@end ifinfo
and the number of different spectrum numbers.
The other three entries are of type @code{intvec}.
They contain the numerators, denominators and
multiplicities of the spectrum numbers. So
@tex
$x^7+y^7+z^7=0$
@end tex
@ifinfo
x^7+y^7+z^7=0
@end ifinfo
has Milnor number 216 and geometrical
genus 35. Its spectrum consists of the 16 different rationals
@*@tex
${3 \over 7}, {4 \over 7}, {5 \over 7}, {6 \over 7}, {1 \over 1},
{8 \over 7}, {9 \over 7}, {10 \over 7}, {11 \over 7}, {12 \over 7},
{13 \over 7}, {2 \over 1}, {15 \over 7}, {16 \over 7}, {17 \over 7},
{18 \over 7}$
@end tex
@ifinfo
3/7, 4/7, 5/7, 6/7, 1, 8/7, 9/7, 10/7, 11/7, 12/7, 13/7, 2, 15/7, 16/7, 17/7, 
18/7
@end ifinfo
@*appearing with multiplicities
@*1,3,6,10,15,21,25,27,27,25,21,15,10,6,3,1.

@tex
The singularities of type $\tilde{E}_6$ form a
$\mu$-constant one parameter family given by
$x^3+y^3+z^3+\lambda xyz=0,\quad \lambda^3\neq-27$.
@end tex
@ifinfo
The singularities of type E~_6 form a
mu-constant one parameter family given by
x^3+y^3+z^3+lambda xyz=0, lambda^3 <> -27.
@end ifinfo
Therefore they have all the same spectrum, which we compute
for 
@tex
$x^3+y^3+z^3$.
@end tex
@ifinfo
@math{x^3+y^3+z^3}.
@end ifinfo

@smallexample
poly g=x^3+y^3+z^3;
list s2=spectrum(g);
s2;
@expansion{} [1]:
@expansion{}    8
@expansion{} [2]:
@expansion{}    1
@expansion{} [3]:
@expansion{}    4
@expansion{} [4]:
@expansion{}    1,4,5,2
@expansion{} [5]:
@expansion{}    1,3,3,1
@expansion{} [6]:
@expansion{}    1,3,3,1
@end smallexample
Evaluating semicontinuity is very easy:
@smallexample
semic(s1,s2);
@expansion{} 18
@end smallexample

This tells us that there are at most 18 singularities of type
@tex
$\tilde{E}_6$ on a septic in $P^3$. But $x^7+y^7+z^7$
@end tex
@ifinfo
E~_6 on a septic in P^3. But x^7+y^7+z^7
@end ifinfo
is semiquasihomogeneous (sqh), so we can also apply the stronger
form of semicontinuity:

@smallexample
semicsqh(s1,s2);
@expansion{} 17
@end smallexample

So in fact a septic has at most 17 triple points of type
@tex
$\tilde{E}_6$.
@end tex
@ifinfo
E~_6.
@end ifinfo

Note that @code{spectrum(f)} works only if @math{f} has nondegenerate
principal part. In fact @code{spectrum} will detect a degenerate
principal part in many cases and print out an error message.
However if it is known in advance that @math{f} has nondegenerate
principal part, then the spectrum may be computed much faster
using @code{spectrum(f,1)}.

@c ---------------------------------------------------------------------------
@node Toric ideals and Integer Programming, References, The spectrum, Mathematical background
@section Toric ideals and Integer Programming
@cindex Toric ideals and Integer Programming

@menu
* Toric ideals::                Definition and computation.
* Integer Programming::         An algorithm using toric ideals. 
@end menu

@c ---------------------------------------------------------------------------
@node Toric ideals, Integer Programming, , Toric ideals and Integer Programming

@subsection Toric ideals
@cindex toric ideals
@cindex ideal, toric

Let @math{A} denote an m x n matrix with integral coefficients. For
@tex 
$u \in Z\!\!\! Z^n$, we define $u^+,u^-$
@end tex
@ifinfo
u in Z^n
@end ifinfo
to be the uniquely determined
vectors with nonnegative coefficients and disjoint support (i.e.,
@tex
$u_i^+=0$ or $u_i^-=0$ for each component $i$)
$u=u^+-u^-$. For $u\geq 0$ component-wise, let $x^u$ denote the monomial
$x_1^{u_1}\cdot\ldots\cdot x_n^{u_n}\in K[x_1,\ldots,x_n]$.  
@end tex
@ifinfo
u+[i]=0 or u-[i]=0 for each component i) such that u = u+ - u-. 
For u>=0 component-wise, let x^u
denote the monomial x(1)^u[1] *@dots{}* x(n)^u[n] in K[x(1),@dots{},x(n)]. 
@end ifinfo

The ideal  
@tex
$$ I_A:=<x^{u^+}-x^{u^-} | u\in\ker(A)\cap Z\!\!\! Z^n>\ \subset
K[x_1,\ldots,x_n] $$  
@end tex
@ifinfo
in K[x(1),@dots{},x(n)] @*
@display 
I(A):= < x^u+ - x^u- | u in ker(A), u in Z^n > 
@end display 
@end ifinfo
is called a @strong{toric ideal}.

The first problem in computing toric ideals is to find a finite
generating set: Let v(1),@dots{},v(r) be a lattice basis of ker(A) as a
subset of Z^n (i.e., a basis of the Z-module). Then @* 
@display 
I(A):= sat( I, x[1] *@dots{}* x[n]) 
@end display
where @*
@display 
I= < x^v(i)+ - x^v(i)- | i=1,@dots{},r >. 
@end display 

The required lattice basis can be computed using the LLL-algorithm (see
[Coh93]). For the computation of the saturation, there are various
possibilities described in the menu entry Algorithms.  

@menu
* Algorithms::             Various algorithms for computing toric ideals.
* Buchberger algorithm::   Specializing it for toric ideals.
@end menu

@c -----------------------------------------------------------------------
@node Algorithms, Buchberger algorithm, , Toric ideals
@cindex Algorithms
@subsubsection Algorithms

@menu
* Conti and Traverso::                 
* Pottier::                 
* Hosten and Sturmfels::                 
* Di Biase and Urbanke::                 
* Bigatti and La Scala and Robbiano::                 
@end menu

@c -----------------------------------------------------------------------
@node Conti and Traverso, Pottier, , Algorithms
@strong{The algorithm of Conti and Traverso}
@cindex Conti-Traverso algorithm
@cindex algorithm of Conti and Traverso

@tex
The algorithm of Conti and Traverso ([CoTr91]) computes $I_A$ in a
somewhat different way. It starts with the extended matrix $B=(I_m|A)$,
where $I_m$ is the $m\times m$ unity matrix. A lattice basis of $B$ is
given by the set of vectors $(a^j,-e_j)\in Z\!\!\! Z^{m+n}$, where $e_j$
ist the $j$-th coordinate vector and $a^j$ the $j$-th row of $A$. We
look at the ideal in $K[y_1,\ldots,y_m,x_1,\ldots,x_n]$ corresponding to
these vectors, namely
$$ I_1=<y^{a_j^+}- x_j y^{a_j^-} | j=1,\ldots, n>.$$
We introduce a further variable $t$ and adjoin the binomial $t\cdot
y_1\cdot\ldots\cdot y_m -1$ to the generating set of $I_1$, obtaining
an ideal $I_2$ in the polynomial ring $K[t,
y_1,\ldots,y_m,x_1,\ldots,x_n]$. $I_2$ is saturated w.r.t.@: all
variables, because all variables are invertible modulo $I_2$. Now $I_A$
can be computed from $I_2$ by eliminating the variables
$t,y_1,\ldots,y_m$.  
@end tex

@ifinfo
The algorithm of Conti and Traverso ([CoTr91]) computes I(A) in a
somewhat different way. It starts with the extended matrix B= ( I | A ),
where I is the mxm unity matrix. A lattice basis of B is given by the
set of vectors (a^j,-e_j) in Z^(m+n), where e_j ist the j-th coordinate
vector and a^j the j-th row of A. We look at the ideal in
K[y(1),@dots{},y(m),x(1),@dots{},x(n)] corresponding to these vectors,
namely @*
@display
I1= < y^(a_j)+ - x(j) * y^(a_j)- | j=1,@dots{},n >.
@end display
We introduce a further variable t and adjoin the binomial t * y(1)
*@dots{}* y(m) -1 to the generating set of I1, obtaining an ideal I2 in
the polynomial ring K[t,y(1),@dots{},y(m),x(1),@dots{},x(n)]. I2 is
saturated w.r.t.@: all variables, because all variables are invertible
modulo I2. Now I(A) can be computed from I2 by eliminating the variables
t,y(1),@dots{},y(m).  
@end ifinfo

Because of the big number of auxiliary variables needed to compute a
toric ideal, this algorithm is rather slow in practice. However, it has
a special importance in the application to integer programming
(@pxref{Integer Programming}).  

@c ---------------------------------------------------------------------
@node Pottier, Hosten and Sturmfels, Conti and Traverso, Algorithms
@strong{The algorithm of Pottier}
@cindex Pottier algorithm
@cindex algorithm of Pottier

@tex
The algorithm of Pottier ([Pot94]) starts by computing a lattice basis
$v_1,\ldots,v_r$ for the integer kernel of $A$ using the
LLL-algorithm. The ideal corresponding to the lattice basis vectors 
$$ I_1=<x^{v_i^+}-x^{v_i^-}|i=1,\ldots,r> $$
is saturated -- as in the algorithm of Conti and Traverso -- by
inversion of all variables. One adds an auxiliary variable $t$ and the
generator $t\cdot x_1\cdot\ldots\cdot x_n -1$ to obtain an ideal $I_2$
in $K[t,x_1,\ldots,x_n]$ from which one computes $I_A$ by elimination of
$t$. 
@end tex

@ifinfo
The algorithm of Pottier ([Pot94]) starts by computing a lattice basis
v(1),@dots{},v(r) for the integer kernel of A using the
LLL-algorithm. The ideal corresponding to the lattice basis vectors @*
@display
I1= < x^v(i)+ - x^v(i)- | i=1,@dots{},r > 
@end display
is saturated -- as in the algorithm of Conti and Traverso -- by
inversion of all variables. One adds an auxiliary variable t and the
generator t * x(1) *@dots{}* x(n) -1 to obtain an ideal I2 in
K[t,x(1),@dots{},x(n)] from which one computes I(A) by elimination of
t. 
@end ifinfo

@c ---------------------------------------------------------------------
@node Hosten and Sturmfels, Di Biase and Urbanke, Pottier, Algorithms
@strong{The algorithm of Hosten and Sturmfels}
@cindex Hosten-Sturmfels algorithm
@cindex algorithm of Hosten and Sturmfels 

@tex
The algorithm of Hosten and Sturmfels ([HoSt95]) allows to compute $I_A$
without any auxiliary variables, provided that $A$ contains a vector $w$
with positive coefficients in its row space. This is a real restriction,
i.e., the algorithm will not necessarily work in the general case.  

A lattice basis $v_1,\ldots,v_r$ is again computed via the
LLL-algorithm. The saturation step is performed in the following way:
First note that $w$ induces a positive grading w.r.t.@: which the ideal 
$$ I=<x^{v_i^+}-x^{v_i^-}|i=1,\ldots,r> $$
corresponding to our lattice basis is homogeneous. We use the following
lemma: 

Let $I$ be a homogeneous ideal w.r.t. the weighted reverse
lexicographical ordering with weight vector $w$ and variable order $x_1
> x_2 > \ldots > x_n$. Let $G$ denote a Groebner basis of $I$ w.r.t. to
this ordering.  Then a Groebner basis of $(I:x_n^\infty)$ is obtained by
dividing each element of $G$ by the highest possible power of $x_n$. 

From this fact, we can succesively compute 
$$ I_A= I:(x_1\cdot\ldots\cdot x_n)^\infty
=(((I:x_1^\infty):x_2^\infty):\ldots :x_n^\infty); $$ 
in the $i$-th step we take $x_i$ as the cheapest variable and apply the
lemma with $x_i$ instead of $x_n$.  

This procedure involves $n$ Groebner basis computations. Actually, this
number can be reduced to at most $n/2$ (see [HoSh98]), and the single
computations -- except from the first one -- show to be easy and fast in
practice. 
@end tex

@ifinfo
The algorithm of Hosten and Sturmfels ([HoSt95]) allows to compute I(A)
without any auxiliary variables, provided that A contains a vector w
with positive coefficients in its row space. This is a real restriction,
i.e., the algorithm will not necessarily work in the general case.  

A lattice basis v(1),@dots{},v(r) is again computed via the
LLL-algorithm. The saturation step is performed in the following way:
First note that w induces a positive grading w.r.t.@: which the ideal @*
@display
I= < x^v(i)+ - x^v(i)- | i=1,@dots{},r >
@end display 
corresponding to our lattice basis is homogeneous. We use the following
lemma: 

Let I be a homogeneous ideal w.r.t. the weighted reverse lexicographical
ordering with weight vector w and variable order x(1) > x(2) > @dots{} >
x(n). Let G denote a Groebner basis of I w.r.t. to this ordering.  Then
a Groebner basis of sat(I,x(n)) is obtained by dividing each element
of G by the highest possible power of x(n). 

From this fact, we can succesively compute @*
@display
I(A)= sat(I, x(1) *@dots{}* x(n)) 
@ @ @ @ = sat(@dots{}(sat(sat(I,x(1)), x(2)), @dots{}, x(n)));  
@end display
in the i-th step we take x(i) as the cheapest variable and apply the
lemma with x(i) instead of x(n).  

This procedure involves n Groebner basis computations. Actually, this
number can be reduced to at most n/2 (see [HoSh98]), and the single
computations -- except from the first one -- show to be easy and fast in
practice. 
@end ifinfo
      
@c -----------------------------------------------------------------
@node Di Biase and Urbanke, Bigatti and La Scala and Robbiano, Hosten and Sturmfels, Algorithms 

@strong{The algorithm of Di Biase and Urbanke}
@cindex Di Biase-Urbanke algorithm
@cindex algorithm of Di Biase and Urbanke

@tex
Like the algorithm of Hosten and Sturmfels, the algorithm of Di Biase
and Urbanke ([DBUr95]) performs up to $n/2$ Groebner basis
computations. It needs no auxiliary variables, but a supplementary
precondition; namely, the existence of a vector without zero components
in the kernel of $A$.  

The main idea comes from the following observation:

Let $B$ be an integer matrix, $u_1,\ldots,u_r$ a lattice basis of the
integer kernel of $B$. Assume that all components of $u_1$ are
positive. Then  
$$ I_B=<x^{u_i^+}-x^{u_i^-}|i=1,\ldots,r>, $$ 
i.e., the ideal on the right is already saturated w.r.t.@: all variables.

The algorithm starts by finding a lattice basis $v_1,\ldots,v_r$ of the
kernel of $A$ such that $v_1$ has no zero component. Let
$\{i_1,\ldots,i_l\}$ be the set of indices $i$ with
$v_{1,i}<0$. Multiplying the components $i_1,\ldots,i_l$ of
$v_1,\ldots,v_r$ and the columns $i_1,\ldots,i_l$ of $A$ by $-1$ yields
a matrix $B$ and a lattice basis $u_1,\ldots,u_r$ of the kernel of $B$
that fulfill the assumption of the observation above. We are then able
to compute a generating set of $I_A$ by applying the following
``variable flip'' successively to $i=i_1,\ldots,i_l$:    

Let $>$ be an elimination ordering for $x_i$. Let $A_i$ be the matrix
obtained by multiplying the $i$-th column of $A$ with $-1$. Let  
$$\{x_i^{r_j} x^{a_j} - x^{b_j} | j\in J \}$$ 
be a Groebner basis of $I_{A_i}$ w.r.t.@: $>$ (where $x_i$ is neither
involved in $x^{a_j}$ nor in $x^{b_j}$). Then  
$$\{x^{a_j} - x_i^{r_j} x^{b_j} | j\in J \}$$
is a generating set for $I_A$. 
@end tex

@ifinfo
Like the algorithm of Hosten and Sturmfels, the algorithm of Di Biase
and Urbanke ([DBUr95]) performs up to n/2 Groebner basis
computations. It needs no auxiliary variables, but a supplementary
precondition; namely, the existence of a vector without zero components
in the kernel of A.  
 
The main idea comes from the following observation:

Let B be an integer matrix, u(1),@dots{},u(r) a lattice basis of the
integer kernel of B. Assume that all components of u(1) are
positive. Then @*
@display 
I(B)= < x^u(i)+ - x^u(i)- | i=1,@dots{},r >,  
@end display
i.e., the ideal on the right is already saturated w.r.t.@: all variables.

The algorithm starts by finding a lattice basis v(1),@dots{},v(r) of the
kernel of A such that v(1) has no zero component. Let @{ i1,@dots{},il
@} be the set of indices i with v(1)_i <0. Multiplying the components
i1,@dots{},il of v(1),@dots{},v(r) and the columns i1,@dots{},il of A by
-1 yields a matrix B and a lattice basis u(1),@dots{},u(r) of the kernel
of B that fulfill the assumption of the observation above. We are then
able to compute a generating set of I(A) by applying the following
``variable flip'' successively to i=i1,@dots{},il:    

Let > be an elimination ordering for x(i). Let A(i) be the matrix
obtained by multiplying the i-th column of A with -1. Let @*
@display 
@{ x(i)^r(j) * x^a(j) - x^b(j) | j in J @}
@end display
be a Groebner basis of I(A(i)) w.r.t.@: > (where x(i) is neither
involved in x^a(j) nor in x^b(j)). Then @*
@display  
@{ x^a(j) - x(i)^r(j) * x^b(j) | j in J @}
@end display
is a generating set for I(A). 
@end ifinfo

@c ---------------------------------------------------------------------------
@node Bigatti and La Scala and Robbiano, , Di Biase and Urbanke, Algorithms 
@strong{The algorithm of Bigatti, La Scala and Robbiano}
@cindex Bigatti-La Scala-Robbiano algorithm
@cindex algorithm of Bigatti, La Scala and Robbiano

The algorithm of Bigatti, La Scala and Robbiano ([BLR98]) combines the ideas of
the algorithms of Pottier and of Hosten and Sturmfels. The
computations are performed on a graded ideal with one auxiliary
variable 
@tex
$u$ and one supplementary generator $x_1\cdot\ldots\cdot x_n - 
u$ (instead of the generator $t\cdot x_1\cdot\ldots\cdot x_n -1$ in
the Pottier algorithm). The algorithm uses a quite unusual technique to
get rid of the variable $u$ again.
@end tex
@ifinfo
u and one supplementary generator x(1) *@dots{}* x(n) -u (instead of the
generator t * x(1) *@dots{}* x(n) -1 in 
the Pottier algorithm). The algorithm uses a quite unusual technique to
get rid of the variable u again.
@end ifinfo

There is another algorithm of the authors which tries to parallelize
the computations (but which is not implemented in this library).   

@c ---------------------------------------------------------------------------
@node Buchberger algorithm, , Algorithms, Toric ideals
@subsubsection Buchberger algorithm for toric ideals
@cindex Buchberger algorithm for toric ideals

Toric ideals have a very special structure that allows us to improve
the Buchberger algorithm in many respects: They are prime ideals and
generated by binomials. Pottier used this fact to describe all
operations of the Buchberger algorithm on the ideal generators in terms
of vector additions and subtractions. Some other strategies like
multiple reduction ([CoTr91]) or the use of bit 
vectors to represent the support of a monomial ([Big97]) may be
applied to more general ideals, but show to 
be especially useful in the toric case.

@c ---------------------------------------------------------------------------
@node Integer Programming, References, Toric ideals, Mathematical background
@subsection Integer Programming
@cindex integer Programming

@tex
Let $A$ be an $m\times n$ matrix with integral coefficients, $b\in
Z\!\!\! Z^m$ and $c\in Z\!\!\! Z^n$. The problem
$$ \min\{c^T x | x\in Z\!\!\! Z^n, Ax=b, x\geq 0\hbox{
component-wise}\} $$
is called an instance of the \bf integer programming problem \rm or
\bf IP problem. \rm 

The IP problem is very hard; namely, it is NP-complete. 

For the following discussion let $c\geq 0$ (component-wise). We
consider $c$ as a weight vector; because of its nonnegativity, $c$ can 
be refined into a monomial ordering $>_c$. It turns out that we can
solve such an IP instance with the help of toric ideals:

First we assume that an initial solution $v$ (i.e., $v\in Z\!\!\!
Z^n, v\geq 0, Av=b$) is already known. We obtain the optimal solution
$v_0$ (i.e., with $c^T v_0$ minimal) by the following procedure:

@itemize
\item {(1)} Compute the toric ideal $I_A$ using one of the algorithms in the 
      previous section.
\item {(2)} Compute the reduced Groebner basis $G_c$ of $I_A$ w.r.t.@:
      $>_c$. 
\item {(3)} Reduce $x^v$ modulo $G_c$ using the Hironaka division algorithm.
      If the result of this reduction is $x^{v_0}$, then $v_0$ is an
      optimal solution of the given instance.  
@end itemize
@end tex

@ifinfo
Let A be an mxn matrix with integral coefficients, b in Z^m and c in
Z^n. The problem @*
@display
min @{ c*x | x in Z^n, A*x=b, x>=0 component-wise @} 
@end display
is called an instance of the @strong{integer programming problem} or
@strong{IP problem}.   

The IP problem is very hard; namely, it is NP-complete. 

For the following discussion let c>=0 (component-wise). We
consider c as a weight vector; because of its nonnegativity, c can 
be refined into a monomial ordering >_c. It turns out that we can
solve such an IP instance with the help of toric ideals:

First we assume that an initial solution v (i.e., v in Z^n, v>=0,
A*v=b) is already known. We obtain the optimal solution v(opt) (i.e.,
with c*v(opt) minimal) by the following procedure: 

@itemize @bullet
@item (1) Compute the toric ideal I(A) using one of the algorithms in the previous section.
@item (2) Compute the reduced Groebner basis G(c) of I(A) w.r.t.@: >_c. 
@item (3) Reduce x^v modulo G(c) using the Hironaka division algorithm. If the result of this reduction is x^v(opt), then v(opt) is an optimal solution of the given instance.  
@end itemize
@end ifinfo

If no initial solution is known, we are nevertheless able to solve the 
problem with similar techniques. For this purpose we replace our
instance by an extended instance with the same extended matrix as
needed in the Conti-Traverso algorithm. Indeed, the Conti-Traverso
algorithm offers the possibility to verify solvability of a given
instance and to find an initial solution in the case of existence (but 
none of the other algorithms does!). Details can be found in [CoTr91]
and [The99].

Classical methods for solving IP instances like Branch-and-Bound
methods seem to be faster in general than the methods using toric
ideals. But the latter have one great advantage: If one wants to solve 
various instances that differ only by the vector @math{b}, one has to
perform steps (1) and (2) above only once. As the running time of step (3)
is very short, solving all the instances is not much harder than
solving only a single instance. 

For a detailed discussion see [The99].

@c ---------------------------------------------------------------------------
@node References, , Toric ideals and Integer Programming, Mathematical background
@section References
@cindex References

The Centre for Computer Algebra Kaiserslautern publishes a series of preprints
which are electronically available at
@code{http://www.mathematik.uni-kl.de/~zca/Reports_on_ca}.
Other sources to check are @code{http://symbolicnet.mcs.kent.edu/},
@code{http://www.can.nl/},... and the following list of books:

@subheading Text books on computational algebraic geometry
@itemize @bullet

@item
Adams, W.; Loustaunau, P.: An Introduction to Gr@"obner Bases. Providence, RI,
AMS, 1996

@item
Becker, T.; Weisspfenning, V.:
Gr@"obner Bases - A Computational Approach to Commutative Algebra. Springer, 1993

@item
Cohen, H.:
A Course in Computational Algebraic Number Theory,
Springer, 1995

@item
Cox, D.; Little, J.; O'Shea, D.:
Ideals, Varieties and Algorithms. Springer, 1996

@item
Eisenbud, D.: Commutative Algebra with a View Toward Algebraic Geometry.
Springer, 1995

@item
Mishra, B.: Algorithmic Algebra, Texts and Monographs in Computer Science.
Springer, 1993
@item
Sturmfels, B.: Algorithms in Invariant Theory. Springer 1993

@item
Vasconcelos, W.: Computational Methods in Commutative Algebra and Algebraic
Geometry. Springer, 1998
@end itemize

@subheading Descriptions of algorithms
@itemize @bullet
@item
Bareiss, E.:
Sylvester's identity and multistep integer-preserving Gaussian elimination.
Math. Comp. 22 (1968), 565-578

@item
Campillo, A.: Algebroid curves in positive characteristic. SLN 813, 1980

@item
Chou, S.:
Mechanical Geometry Theorem Proving.
D.Reidel Publishing Company, 1988

@item
Decker, W.; Greuel, G.-M.; Pfister, G.:
Primary decomposition: algorithms and
comparisons.  Preprint, Univ. Kaiserslautern, 1998.
To appear in: Greuel, G.-M.; Matzat, B. H.; Hiss, G. (Eds.),
Algorithmic Algebra and Number Theory. Springer Verlag, Heidelberg, 1998

@item
Decker, W.; Greuel, G.-M.; de Jong, T.; Pfister, G.:
The normalisation: a new algorithm,
implementation and comparisons. Preprint, Univ. Kaiserslautern, 1998

@item
Decker, W.; Heydtmann, A.; Schreyer, F. O.: Generating a Noetherian Normalization of
the Invariant Ring of a Finite Group, 1997, to appear in Journal of
Symbolic Computation

@item
@tex
Faug\`ere,
@end tex
@ifinfo
Faugere,
@end ifinfo
J. C.; Gianni, P.; Lazard, D.; Mora, T.: Efficient computation
of zero-dimensional
Gr@"obner bases by change of ordering. Journal of Symbolic Computation, 1989

@item
Gr@"abe, H.-G.: On factorized Gr@"obner bases, Univ. Leipzig, Inst. f@"ur
Informatik, 1994

@item
Grassmann, H.; Greuel, G.-M.; Martin, B.; Neumann,
W.; Pfister, G.; Pohl, W.; Sch@"onemann, H.; Siebert, T.:  On an
implementation of standard bases and syzygies in  @sc{Singular}.
Proceedings of the Workshop  Computational Methods in Lie theory in AAECC (1995)

@item
Greuel, G.-M.; Pfister, G.:
Advances and improvements in the theory of standard bases and
syzygies. Arch. d. Math. 63(1995)

@item
Kemper; Generating Invariant Rings of Finite Groups over Arbitrary
Fields. 1996, to appear in Journal of Symbolic Computation

@item
Kemper and Steel: Some Algorithms in Invariant Theory of Finite Groups. 1997

@item
Lee, H.R.; Saunders, B.D.: Fraction Free Gaussian Elimination for
Sparse Matrices. Journal of Symbolic Computation (1995) 19, 393-402

@item
Sch@"onemann, H.:
Algorithms in @sc{Singular},
Reports on Computer Algebra 2(1996), Kaiserslautern

@item
Siebert, T.:
On strategies and implementations for computations of free resolutions.
Reports on Computer Algebra 8(1996), Kaiserslautern

@item
Wang, D.:
Characteristic Sets and Zero Structure of Polynomial Sets.
Lecture Notes, RISC Linz, 1989
@end itemize

